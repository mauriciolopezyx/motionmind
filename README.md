# Motion Mind

**Motion Mind** is an interactive educational platform that makes STEM learning more accessible, engaging, and fun.  
Built during the CSU East Bay Hackathon, Motion Mind AR combines **gesture recognition**, **physics simulation**, and **AR-inspired gameplay** to teach learners of all ages STEM concepts through hands-on exploration.  

> Use your hands to construct objects and advance through levels

---

## Project Overview
Traditional online learning often struggles with engagement, especially in STEM subjects.  
**Motion Mind** bridges this gap by blending:
- **Gesture-based interaction** â†’ players build and manipulate virtual objects using hand motions.
- **Physics-based gameplay** â†’ solving puzzles requires applying real-world STEM concepts in-game such as force, friction, and gravity.
- **Course progression** â†’ structured levels ensure a gradual, rewarding learning experience (Planned)

**Goal:**
> To inspire curiosity and kinesthetic learning in STEM through immersive, interactive technology.

---

## Tech Stack
This project spans multiple technologies, each responsible for a key part of the pipeline:

### Frontend
- **Next.js** â€“ Hosts the web interface. (planned: integrates Unity WebGL build)
- **React** â€“ Responsive UI for authentication and course progression.
- **TailwindCSS** â€“ Rapid styling and prototyping.

### Backend
- **Spring Boot** â€“ Manages user state, login, verification, authentication, course progression, and serves API for Unity.
- **WebSockets (STOMP and SockJS)** â€“ Real-time communication between services and clients.
- **Supabase** â€“ Stores authentication and persistent user progress information

### Machine Learning
- **Flask** â€“ serves the machine learning model API for gesture recognition.
- **MediaPipe / OpenCV** â€“ Used to capture and classify static hand gestures.
- **Custom lightweight CNN** â€“ Predicts gesture categories (e.g. ladder, cube, ramp).

### Game Engine
- **Unity (planned: WebGL Export)** â€“ Physics-driven game environment embedded in the Next.js app.
- Players use gestures to spawn Unity primitives (cube, ladder, ramp, etc.) and interact with them through natural physics.

---

## ðŸ“‚ Repository Structure
```plaintext
.
â”œâ”€â”€ mm-frontend/        # Next.js frontend
â”œâ”€â”€ mm-backend/         # Spring Boot backend
â”œâ”€â”€ mm-flask/          # Flask setup which includes ML API
â””â”€â”€ README.md
